{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea337813-fce5-4417-b59b-dc0d15fab55e",
   "metadata": {
    "id": "ea337813-fce5-4417-b59b-dc0d15fab55e"
   },
   "source": [
    "# Deep Learning - Report 1\n",
    "This is a template notebook of your report. Please complete your report with your team mate following these instructions:\n",
    "- Work on the exercies below by filling the notebook.\n",
    "- **Rename your notebook** in the format `FirstName1FAMILYNAME1_FirstName2FAMILYNAME2_report1.ipynb`. For example, when the team consists of Johann FAOUZI and Ikko Yamane, the file name should look like `JohannFAOUZI_IkkoYAMANE_report1.ipynb`.\n",
    "- You are only allowed to edit new cells you have added (except the \"Solution to Exercise 0\" cell).\n",
    "- Write `### Solution to Exercise (number)` at the beginning of each cell you add.\n",
    "- Please submit your notebook on Moodle.\n",
    "- The submission deadline is 17:00 (UTC+2) of September 19, 2023.\n",
    "- Explain your code with comment or/and markdown. The explanations will be taken into account for the evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794f604e-1919-45c0-8fed-31d0c128327c",
   "metadata": {
    "id": "794f604e-1919-45c0-8fed-31d0c128327c"
   },
   "source": [
    "## Exercise 0\n",
    "- Rename your notebook in the format `FirstName1FAMILYNAME1_FirstName2FAMILYNAME2_report1.ipynb`.\n",
    "- Write your names and email addresses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46bbec6f-db8a-45d6-972a-282f11e2c383",
   "metadata": {
    "id": "46bbec6f-db8a-45d6-972a-282f11e2c383"
   },
   "source": [
    "### Solution to Exercise 0\n",
    "- Name of Author 1:\n",
    "- Name of Author 2:\n",
    "- Email address of Author 1:\n",
    "- Email address of Author 2:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac3d7fe-0654-415f-8fb3-cfb1007bda14",
   "metadata": {
    "id": "0ac3d7fe-0654-415f-8fb3-cfb1007bda14"
   },
   "source": [
    "## CIFAR-10\n",
    "We are going to work on the [CIFAR-10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html) [Krizhevsky 2009].\n",
    "\n",
    "For the purpose of testing your skills, we are going to directly download an original dataset and manually adapt it to the PyTorch format. The following three cells download the data, create NumPy arrays of them, and show examples. The `load_cifar10` function converts the color images to gray-scale ones when `color=False`.\n",
    "\n",
    "[Krizhevsky 2009] [Learning Multiple Layers of Features from Tiny Images, Alex Krizhevsky, 2009.](https://www.cs.toronto.edu/~kriz/learning-features-2009-TR.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "3dc9eab2-e508-4bb2-b50b-13c83f57531b",
   "metadata": {
    "id": "3dc9eab2-e508-4bb2-b50b-13c83f57531b"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "import tarfile\n",
    "import os.path\n",
    "from pathlib import Path\n",
    "\n",
    "def download_cifar10():\n",
    "    filename = 'cifar-10.tar.gz'\n",
    "    if os.path.isfile(filename):\n",
    "        print(f'{filename} already exists. Skipping downloading.')\n",
    "        return\n",
    "\n",
    "    url = 'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz'\n",
    "\n",
    "    with urllib.request.urlopen(url) as testfile, open('cifar-10.tar.gz', 'wb') as f:\n",
    "        f.write(testfile.read())\n",
    "\n",
    "\n",
    "def extract_cifar10(filename=\"cifar-10.tar.gz\"):\n",
    "    dirname = 'cifar-10-batches-py'\n",
    "    if Path(dirname).is_dir():\n",
    "        print(f'{dirname} already exists. Skipping extracting.')\n",
    "        return\n",
    "\n",
    "    tar = tarfile.open(filename)\n",
    "    tar.extractall()\n",
    "    tar.close()\n",
    "\n",
    "\n",
    "def load_cifar10(train, dir='cifar-10-batches-py', color=False):\n",
    "    data_raw = []\n",
    "    if train:\n",
    "        for i in range(5):\n",
    "            with open(f'{dir}/data_batch_{i+1}', 'rb') as f:\n",
    "                data_raw.append(pickle.load(f, encoding='bytes'))\n",
    "        x = np.concatenate(\n",
    "            [d[b'data'] for d in data_raw],\n",
    "            axis=0)\n",
    "        y = np.concatenate(\n",
    "            [d[b'labels'] for d in data_raw],\n",
    "            axis=0)\n",
    "    else:\n",
    "        with open(f'{dir}/test_batch', 'rb') as f:\n",
    "            data_raw = pickle.load(f, encoding='bytes')\n",
    "        x = np.array(data_raw[b'data'])\n",
    "        y = np.array(data_raw[b'labels'])\n",
    "        print(type(data_raw))\n",
    "\n",
    "    x = np.reshape(x, newshape=(len(x), 3, 32, 32))\n",
    "    if not color:\n",
    "        x = x.mean(axis=1, keepdims=True)  # Convert Red-Green-Blue (RGB) images to gray-scale.\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "a43ec81c-28c3-4349-9ebb-3b9252c6146e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a43ec81c-28c3-4349-9ebb-3b9252c6146e",
    "outputId": "00941c9d-fffc-4a15-ea44-e7717fe1e35e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cifar-10.tar.gz already exists. Skipping downloading.\n",
      "cifar-10-batches-py already exists. Skipping extracting.\n",
      "<class 'dict'>\n",
      "[0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "download_cifar10()\n",
    "extract_cifar10()\n",
    "x_train_val_np, y_train_val_np = load_cifar10(train=True)\n",
    "x_test_np, y_test_np = load_cifar10(train=False)\n",
    "print(np.unique(y_train_val_np))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "066184ca-ee34-49ce-b848-e5dd4e02c3f6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "id": "066184ca-ee34-49ce-b848-e5dd4e02c3f6",
    "outputId": "2fc3963c-4bba-425c-9e34-4ec7e23f83a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['truck', 'truck', 'deer', 'automobile', 'automobile']\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x200 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "id2class = {\n",
    "    0: 'airplane',\n",
    "    1: 'automobile',\n",
    "    2: 'bird',\n",
    "    3: 'cat',\n",
    "    4: 'deer',\n",
    "    5: 'dog',\n",
    "    6: 'frog',\n",
    "    7: 'horse',\n",
    "    8: 'ship',\n",
    "    9: 'truck'\n",
    "}\n",
    "\n",
    "def plot_images(x, y, rows=1, cols=5, color=False):\n",
    "    figure = plt.figure(figsize=(2 * cols, 2 * rows))\n",
    "    ys = []\n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            k = (i * cols) + j + 1\n",
    "            figure.add_subplot(rows, cols, k)\n",
    "            plt.axis(\"off\")\n",
    "            if color:\n",
    "                plt.imshow(np.transpose(x[k], [1, 2, 0]))\n",
    "            else:\n",
    "                plt.imshow(np.transpose(x[k], [1, 2, 0]), cmap=\"gray\")\n",
    "            ys.append(y[k])\n",
    "    print([id2class[id] for id in ys])\n",
    "    plt.show()\n",
    "\n",
    "plot_images(x_train_val_np, y_train_val_np, rows=1, cols=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "6daf098a-b6f7-4c83-bc7c-f3f2275ea1e3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6daf098a-b6f7-4c83-bc7c-f3f2275ea1e3",
    "outputId": "a577eb60-ad95-4045-b8e7-24e750d52728",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.transforms.v2 import ToDtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee7685e-d3ba-45e5-80a0-d48c2b61e2b7",
   "metadata": {
    "id": "5ee7685e-d3ba-45e5-80a0-d48c2b61e2b7"
   },
   "source": [
    "## Exercise 1\n",
    "Randomly split the dataset `(x_train_val_np, y_train_val_np)` to a training set `(x_train_np, y_train_np)` and a validation set `(x_val_np, y_val_np)`. Here, take `40000` data points for the training set and put the rest in the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "708d2a8c-b913-44f6-a0fa-f24d893a13a6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "708d2a8c-b913-44f6-a0fa-f24d893a13a6",
    "outputId": "4d125174-88d7-4d27-f58c-5fbe89322ebf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n"
     ]
    }
   ],
   "source": [
    "x_train_np, x_val_np, y_train_np, y_val_np = train_test_split(\n",
    "    x_train_val_np, y_train_val_np, train_size=40000,\n",
    "    stratify=y_train_val_np, random_state=43\n",
    ")\n",
    "classes, counts = np.unique(y_train_np, return_counts=True)\n",
    "print(counts/counts.sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e58f419-f656-4f59-adb7-ebbf7463600b",
   "metadata": {},
   "source": [
    "The result of train_test_split will be stored in four variables : Two subsets of features for training and validation and two subset of features for training and validation. We don't really need the stratification here because each class have the same proportion. Shuffle ensure that the training and the validation sets are random from the original set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e282dd87-695e-4cbc-b5de-bd9fdbc14bf2",
   "metadata": {
    "id": "e282dd87-695e-4cbc-b5de-bd9fdbc14bf2"
   },
   "source": [
    "## Exercise 2\n",
    "Write code to convert `x_train_np, y_train_np, x_val_np, y_val_np, x_test_np, y_test_np` to PyTorch Tensors.\n",
    "Name the tensors as `x_train, y_train, x_val, y_val, x_test, y_test`, respectively.\n",
    "\n",
    "**Note**: You may need to explicitly change the `dtype` of your tensors. PyTorch by default requires the type (`dtype`) of input tensor to be `torch.float32` and that of the labels to be `torch.int64`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "f658ef6f-01dc-4f97-9149-498d34a33c2d",
   "metadata": {
    "id": "f658ef6f-01dc-4f97-9149-498d34a33c2d"
   },
   "outputs": [],
   "source": [
    "x_train = torch.from_numpy(x_train_np).to(dtype=torch.float32)\n",
    "y_train = torch.from_numpy(y_train_np).to(dtype=torch.int64)  # Class labels are usually integers\n",
    "\n",
    "x_val = torch.from_numpy(x_val_np).to(dtype=torch.float32)\n",
    "y_val = torch.from_numpy(y_val_np).to(dtype=torch.int64)\n",
    "\n",
    "x_test = torch.from_numpy(x_test_np).to(dtype=torch.float32)\n",
    "y_test = torch.from_numpy(y_test_np).to(dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e29f160-2b66-4c6e-8443-b1c13067d6d9",
   "metadata": {
    "id": "0e29f160-2b66-4c6e-8443-b1c13067d6d9"
   },
   "source": [
    "## Exercise 3\n",
    "Write a Python class `CustomDataset` deriving `torch.utils.data.Dataset` and create dataloaders for the training, validation, and test sets.\n",
    "\n",
    "**Bonus** If possible, making the `transform` parameter and pass `ToTensor()` to it to avoid manually converting data to PyTorch tensors as in Exercise 2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5036934-a1f6-4a8b-ad14-0a00eeeafedf",
   "metadata": {
    "id": "c5036934-a1f6-4a8b-ad14-0a00eeeafedf"
   },
   "source": [
    "## Bonus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36736baf-54f9-45c9-b42e-a3edbd7c86aa",
   "metadata": {},
   "source": [
    "# Without transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "2Lidba7vCeOt",
   "metadata": {
    "id": "2Lidba7vCeOt"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "########## avec les tenseurs. ##############\n",
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self,x,y):\n",
    "        self.x=x\n",
    "        self.y=y\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.y.size()[0]\n",
    "# size()[0] return the dimension of the target because it is one dimensional\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        x=self.x[idx]\n",
    "        y=self.y[idx]\n",
    "        return(x,y)\n",
    "\n",
    "\n",
    "train= DataLoader(CustomDataset(x_train,y_train), batch_size=64, shuffle =True)\n",
    "test = DataLoader(CustomDataset(x_test,y_test), batch_size=64, shuffle =True)\n",
    "val = DataLoader(CustomDataset(x_val,y_val), batch_size=64, shuffle =True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9b58a5-c090-418c-926e-96b2a061a2c2",
   "metadata": {},
   "source": [
    "# With transform to tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "e43e3922-5326-4b74-a78e-de20e326f25c",
   "metadata": {
    "id": "e43e3922-5326-4b74-a78e-de20e326f25c"
   },
   "outputs": [],
   "source": [
    "class CustomDatasetNP(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "        This class enable us to return iterable object that can be pass in the \n",
    "        dataloader\n",
    "        It takes three attributes:\n",
    "        x : features\n",
    "        y : targets\n",
    "        y : function that transform the PIL images or numpy.ndarray to a tensor object\n",
    "    \"\"\"\n",
    "    def __init__(self,x,y,transform = None):\n",
    "        self.x=x\n",
    "        self.y=y\n",
    "        self.transform=transform\n",
    "\n",
    "    def __len__(self):\n",
    "        ### le x n'est pas encore un tenseur donc on ne peut pas donner à\n",
    "        ### le .size. La méthode size pour un numpy renvoie le nombre TOTAL d'éléments.\n",
    "        ### Il faut dès lors donner comme longueur .shape[0].\n",
    "        ### c'est à partir de cette longueur que l'on détermine la limite des\n",
    "        ### idx.\n",
    "        ###\n",
    "        return(self.x.shape[0])\n",
    "    def __getitem__(self,idx):\n",
    "        x=self.x[idx]\n",
    "        y=self.y[idx]\n",
    "        if self.transform:\n",
    "            x=self.transform(x).to(dtype=torch.float32)\n",
    "        return(x,y)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_alt = DataLoader(CustomDatasetNP(x_train_np,y_train_np, ToTensor()), batch_size=64, shuffle =True)\n",
    "\n",
    "test_alt = DataLoader(CustomDatasetNP(x_test_np,y_test_np, ToTensor()), batch_size=64, shuffle =True)\n",
    "\n",
    "val_alt = DataLoader(CustomDatasetNP(x_val_np,y_val_np, ToTensor()), batch_size=64, shuffle =True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87425561-86ce-456e-a747-e508a0cb22b3",
   "metadata": {
    "id": "87425561-86ce-456e-a747-e508a0cb22b3"
   },
   "source": [
    "## Exercise 4\n",
    "Let the variable `device` be `'cuda'` if CUDA (GPU) is available. Otherwise, let it be `'cpu'`.\n",
    "(Do **not** move the tensors from Exercise 1 to this `device` yet.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "3fbca087-4535-4152-ae4d-3d394eed3c0f",
   "metadata": {
    "id": "3fbca087-4535-4152-ae4d-3d394eed3c0f"
   },
   "outputs": [],
   "source": [
    "device  = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"cpu\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99fa22fc-91f0-4616-950f-f1cabdaaf170",
   "metadata": {
    "id": "99fa22fc-91f0-4616-950f-f1cabdaaf170"
   },
   "source": [
    "## Exercise 5\n",
    "Write a Python class `MLP5` for Multi-Layer Perceptron (MLP) with 5 layers derivng from `nn.Module` or `nn.Sequencial`.\n",
    "Your network must have the following sequential architecture:\n",
    "- First hidden layer: Linear layer (64 output features) + ReLU activation function\n",
    "- Second hidden layer: Linear layer (64 output features) + ReLU activation function\n",
    "- Third hidden layer: Linear layer (64 output features) + ReLU activation function\n",
    "- Forth hidden layer: Linear layer (64 output features) + ReLU activation function\n",
    "- Final layer: Linear layer\n",
    "\n",
    "Note that the final layer should have the output dimensionality equal to the number of classes in order to express class posterior probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "4312c5d4-1f3f-4ef7-afe7-d00165e9a8d3",
   "metadata": {
    "id": "4312c5d4-1f3f-4ef7-afe7-d00165e9a8d3"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MLP5(nn.Module):\n",
    "    \"\"\"\n",
    "        This is Multi-Layer perceptron(MLP) class which takes one attribute : the number of class of target\n",
    "        number_classes : number of class of target\n",
    "    \"\"\"\n",
    "    def __init__(self, number_classes):\n",
    "        super().__init__()\n",
    "        # We use the flattern to combine two set of information that reduce one dimension to get 32*32\n",
    "        # Sequential enable us to apply sequentially many transformations\n",
    "        self.transform1 = nn.Sequential(nn.Flatten(),nn.Linear(32*32,64),nn.ReLU())\n",
    "        self.transform2 = nn.Sequential(nn.Linear(64,64),nn.ReLU())\n",
    "        self.transform3 = nn.Linear(64,number_classes)\n",
    "    def forward(self,x):\n",
    "        \"\"\"\n",
    "            This function take a tensor object and return the vector of tensor with length : the number of classes\n",
    "            x : tensor object\n",
    "        \"\"\"\n",
    "        out = self.transform1(x)\n",
    "        out = self.transform2(out)\n",
    "        out = self.transform2(out)\n",
    "        out = self.transform2(out)\n",
    "        out = self.transform3(out)\n",
    "\n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78271db-cbcf-4b1b-999a-93ecf3371059",
   "metadata": {},
   "source": [
    "# We have combine the exercice 6 and 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77bddaf1-3077-4f55-9d52-a019520fd30c",
   "metadata": {
    "id": "77bddaf1-3077-4f55-9d52-a019520fd30c"
   },
   "source": [
    "## Exercise 6\n",
    "- Write a Python function for training a model with mini-batch updates for one epoch. Do not forget to move your mini-batch data to `device`.\n",
    "- Also, write Python function for evaluating the loss and the accuracy of a given model with a given dataloader."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89fdcf74-a972-4fb5-b07c-3b3ca488a56b",
   "metadata": {},
   "source": [
    "# Definition of function to using during the DM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "09f8098b-f1a6-40a5-a00a-31243356050e",
   "metadata": {
    "id": "09f8098b-f1a6-40a5-a00a-31243356050e",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Here the definition of the loss function that will enable us to update weight\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "modele_MLP = MLP5(len(id2class)).to(device)\n",
    "learningRate = 1e-7\n",
    "optimizer = torch.optim.Adam(modele_MLP.parameters(), lr= learningRate )\n",
    "\n",
    "# Here the function to train the model\n",
    "\n",
    "def train_loop(dataloader,loss_fn, optimizer, modele,device):\n",
    "    modele.train()\n",
    "    perte_dataloader=0\n",
    "    precision=0\n",
    "    for batch, (X,y) in enumerate(dataloader):\n",
    "        # pour chaque itération, on calcule la fonction de coût.\n",
    "        X=X.to(device)\n",
    "\n",
    "        y=y.to(device)\n",
    "\n",
    "        predictions=modele(X)\n",
    "\n",
    "        perte=loss_fn(predictions,y)\n",
    "\n",
    "        perte.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        optimizer.zero_grad() # update weight\n",
    "\n",
    "        perte_dataloader+=perte.item()\n",
    "\n",
    "    print(batch,perte_dataloader)\n",
    "\n",
    "\n",
    "def evaluate_loop(dataloader, model, loss_fn, device, set_='Validation'):\n",
    "    # Set the model to evaluation mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    # Evaluating the model with torch.no_grad() ensures that no gradients are computed during test mode\n",
    "    # also serves to reduce unnecessary gradient computations and memory usage for tensors with requires_grad=True\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            # Move the tensors to `device`. For instance, it could be a GPU.\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"\\n{set_} set: \\n  Accuracy: {(100 * correct): >0.1f}%, Avg loss: {test_loss: >8f} \\n\")\n",
    "    return (100*correct)\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np \n",
    "import torch as torch\n",
    "\n",
    "list_learning_rate = [0.001, 0.0001, 1e-5,  1e-6, 1e-7, 1e-8,  1e-9]\n",
    "\n",
    "\n",
    "# Function that return the learning rate after the turn\n",
    "\n",
    "def fonction_renvoie_lr_rate(list_learning_rate, device , modele, train, val, number_class, loss_fn):\n",
    "\n",
    "    \"\"\" Renvoyer le meilleur taux. \n",
    "    Parameters :\n",
    "    ---------\n",
    "    list_learning_rate : list. Liste des taux. \n",
    "    device : str. Cpu ou cuda. \n",
    "    modele : modele statistique. Il doit avoir comme attribut le nombre de classes de Y. \n",
    "    train : dataloader pour l'apprentissage. \n",
    "    val : dataloader pour la validation. \n",
    "    number_class : int. Nombre de classes pour Y (longueur(id2classes)) dans le tp.\n",
    "    loss_fn : Function. fonction de coût/loss function. \n",
    "\n",
    "    Returns :\n",
    "    ----\n",
    "    float. Best learning rate. \n",
    "    \"\"\"\n",
    "\n",
    "    liste_precision = []\n",
    "    for taux in list_learning_rate:\n",
    "        # instancier le modèle avec les optimisateurs.\n",
    "        \n",
    "        precision_un_taux = []\n",
    "        if number_class:\n",
    "            modele_MPL = modele(number_class).to(device)\n",
    "        else:\n",
    "             modele_MPL = modele().to(device)\n",
    "        optimizer = torch.optim.Adam(modele_MPL.parameters(), lr=taux)\n",
    "        \n",
    "        print(f\"Le taux de learning est de {taux}\")\n",
    "        \n",
    "        torch.manual_seed(133)  #The function torch.manual_seed() is \n",
    "        #used to initialize PyTorch's random number generator \n",
    "        #with a specific seed, ensuring that the outcomes of operations \n",
    "        #involving random numbers will be reproducible in CPU.\n",
    "\n",
    "\n",
    "        for epoch in range(10):\n",
    "            print(str(epoch)+\"-------------------\")\n",
    "            # fonctions à coder. \n",
    "            train_loop(dataloader=train, optimizer=optimizer, loss_fn=loss_fn, modele=modele_MPL, device=device)\n",
    "            precision = evaluate_loop(dataloader=val, loss_fn=loss_fn, model=modele_MPL, device=device)\n",
    "            precision_un_taux.append(precision)\n",
    "        # on récupère la précision moyenne avec le même taux. \n",
    "        selection = np.mean(np.array(precision_un_taux))\n",
    "        # on ajoute cette moyenne. \n",
    "        liste_precision.append(selection)\n",
    "        # on choisit le taux de précision moyenne maximale. \n",
    "    indice = np.argmax(np.array(liste_precision))\n",
    "    # Fini !\n",
    "    lr_rate_opt = list_learning_rate[indice]\n",
    "    return(lr_rate_opt)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f0f65b-699f-40e4-9db0-e53668b549a8",
   "metadata": {
    "id": "14f0f65b-699f-40e4-9db0-e53668b549a8"
   },
   "source": [
    "## Exercise 7\n",
    "- Create an object using your class and keep it in the `modelMLP5` variable. Do not forget move your model to `device`.\n",
    "- Choose any loss function.\n",
    "- Create an optimizer for optimizing `modelMLP5`.\n",
    "- Train `modelMLP5` with your function(s) for 10 epochs. During the training, print the training and validation loss/accuracy every epoch.\n",
    "\n",
    "You may need to tune hyper-parameters such as the learning rate later while observing the behavior of the model during the training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5817f16c-e05d-4a9f-abd9-bb548e0d3929",
   "metadata": {},
   "source": [
    "# Training of the model with learning rate =  1e-7 chosen randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "kz-gKzImEU7k",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kz-gKzImEU7k",
    "outputId": "79c38777-4d82-4bc5-8700-4a3e2f946112"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0-------------------\n",
      "624 2057.9291501045227\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 9.1%, Avg loss: 3.112059 \n",
      "\n",
      "1-------------------\n",
      "624 1874.33944439888\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 10.0%, Avg loss: 2.904704 \n",
      "\n",
      "2-------------------\n",
      "624 1777.8602333068848\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 10.8%, Avg loss: 2.792529 \n",
      "\n",
      "3-------------------\n",
      "624 1719.864489555359\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 11.4%, Avg loss: 2.714020 \n",
      "\n",
      "4-------------------\n",
      "624 1675.7322175502777\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 11.5%, Avg loss: 2.649324 \n",
      "\n",
      "5-------------------\n",
      "624 1637.2281668186188\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 11.6%, Avg loss: 2.592182 \n",
      "\n",
      "6-------------------\n",
      "624 1602.2093014717102\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 11.8%, Avg loss: 2.538395 \n",
      "\n",
      "7-------------------\n",
      "624 1571.03928399086\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 11.9%, Avg loss: 2.494058 \n",
      "\n",
      "8-------------------\n",
      "624 1544.454086780548\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 12.0%, Avg loss: 2.455312 \n",
      "\n",
      "9-------------------\n",
      "624 1522.7628066539764\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 12.1%, Avg loss: 2.426540 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    print(str(epoch)+\"-------------------\")\n",
    "    train_loop(dataloader=train_alt,optimizer=optimizer,loss_fn=loss_fn,modele=modele_MLP,device=device)\n",
    "    evaluate_loop(dataloader=val_alt,loss_fn=loss_fn,model=modele_MLP,device=device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feeaca24-edd7-4ec7-838c-b5b9f7c91efd",
   "metadata": {},
   "source": [
    "# Turning of the MLP5 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "fd0ee8b8-0362-4630-8dc0-f26d56c41f51",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fd0ee8b8-0362-4630-8dc0-f26d56c41f51",
    "outputId": "98a05137-2297-4e3d-d676-c83b883b8533"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le taux de learning est de 0.001\n",
      "0-------------------\n",
      "624 1314.359148144722\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 26.8%, Avg loss: 1.991418 \n",
      "\n",
      "1-------------------\n",
      "624 1228.080017209053\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 29.8%, Avg loss: 1.945779 \n",
      "\n",
      "2-------------------\n",
      "624 1201.3127753734589\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 31.1%, Avg loss: 1.908072 \n",
      "\n",
      "3-------------------\n",
      "624 1183.404344677925\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 31.5%, Avg loss: 1.916778 \n",
      "\n",
      "4-------------------\n",
      "624 1173.649095773697\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 32.7%, Avg loss: 1.882319 \n",
      "\n",
      "5-------------------\n",
      "624 1160.0710592269897\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 31.1%, Avg loss: 1.921491 \n",
      "\n",
      "6-------------------\n",
      "624 1155.419777393341\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 32.1%, Avg loss: 1.912946 \n",
      "\n",
      "7-------------------\n",
      "624 1142.6775510311127\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 32.5%, Avg loss: 1.876046 \n",
      "\n",
      "8-------------------\n",
      "624 1141.0859252214432\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 33.6%, Avg loss: 1.840461 \n",
      "\n",
      "9-------------------\n",
      "624 1131.5125943422318\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 31.8%, Avg loss: 1.898246 \n",
      "\n",
      "Le taux de learning est de 0.0001\n",
      "0-------------------\n",
      "624 1327.8958134651184\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 26.3%, Avg loss: 2.028919 \n",
      "\n",
      "1-------------------\n",
      "624 1241.5879427194595\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 28.5%, Avg loss: 1.969711 \n",
      "\n",
      "2-------------------\n",
      "624 1204.2130961418152\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 31.3%, Avg loss: 1.915442 \n",
      "\n",
      "3-------------------\n",
      "624 1179.5019606351852\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 31.2%, Avg loss: 1.911156 \n",
      "\n",
      "4-------------------\n",
      "624 1163.8491501808167\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 33.1%, Avg loss: 1.873689 \n",
      "\n",
      "5-------------------\n",
      "624 1150.017021894455\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 33.0%, Avg loss: 1.862330 \n",
      "\n",
      "6-------------------\n",
      "624 1139.9697340726852\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 32.9%, Avg loss: 1.865582 \n",
      "\n",
      "7-------------------\n",
      "624 1129.5699880123138\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 33.6%, Avg loss: 1.841914 \n",
      "\n",
      "8-------------------\n",
      "624 1120.2726575136185\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 34.4%, Avg loss: 1.829516 \n",
      "\n",
      "9-------------------\n",
      "624 1110.9400565624237\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 34.6%, Avg loss: 1.832034 \n",
      "\n",
      "Le taux de learning est de 1e-05\n",
      "0-------------------\n",
      "624 1447.08412027359\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 19.3%, Avg loss: 2.204885 \n",
      "\n",
      "1-------------------\n",
      "624 1341.554961681366\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 23.8%, Avg loss: 2.114946 \n",
      "\n",
      "2-------------------\n",
      "624 1300.1654205322266\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 25.4%, Avg loss: 2.068527 \n",
      "\n",
      "3-------------------\n",
      "624 1276.3968399763107\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 27.2%, Avg loss: 2.043829 \n",
      "\n",
      "4-------------------\n",
      "624 1258.0447010993958\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 28.1%, Avg loss: 2.015033 \n",
      "\n",
      "5-------------------\n",
      "624 1244.3957549333572\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 28.8%, Avg loss: 1.996585 \n",
      "\n",
      "6-------------------\n",
      "624 1232.7741177082062\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 29.7%, Avg loss: 1.989246 \n",
      "\n",
      "7-------------------\n",
      "624 1222.637011051178\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 30.1%, Avg loss: 1.966262 \n",
      "\n",
      "8-------------------\n",
      "624 1214.2012459039688\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 30.2%, Avg loss: 1.960399 \n",
      "\n",
      "9-------------------\n",
      "624 1205.5953859090805\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 30.8%, Avg loss: 1.947826 \n",
      "\n",
      "Le taux de learning est de 1e-06\n",
      "0-------------------\n",
      "624 1694.8804461956024\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 12.1%, Avg loss: 2.437155 \n",
      "\n",
      "1-------------------\n",
      "624 1483.220731496811\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 13.5%, Avg loss: 2.335517 \n",
      "\n",
      "2-------------------\n",
      "624 1448.1268837451935\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 14.4%, Avg loss: 2.302997 \n",
      "\n",
      "3-------------------\n",
      "624 1430.8570890426636\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 15.2%, Avg loss: 2.280661 \n",
      "\n",
      "4-------------------\n",
      "624 1417.5717296600342\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 16.4%, Avg loss: 2.260299 \n",
      "\n",
      "5-------------------\n",
      "624 1406.2873787879944\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 16.9%, Avg loss: 2.244973 \n",
      "\n",
      "6-------------------\n",
      "624 1396.050615787506\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 17.7%, Avg loss: 2.230224 \n",
      "\n",
      "7-------------------\n",
      "624 1386.4906914234161\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 18.4%, Avg loss: 2.214589 \n",
      "\n",
      "8-------------------\n",
      "624 1377.5354375839233\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 19.2%, Avg loss: 2.201650 \n",
      "\n",
      "9-------------------\n",
      "624 1369.0223479270935\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 20.0%, Avg loss: 2.189943 \n",
      "\n",
      "Le taux de learning est de 1e-07\n",
      "0-------------------\n",
      "624 2039.502180814743\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 9.8%, Avg loss: 3.093345 \n",
      "\n",
      "1-------------------\n",
      "624 1865.5112307071686\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 10.3%, Avg loss: 2.890991 \n",
      "\n",
      "2-------------------\n",
      "624 1770.1555869579315\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 10.7%, Avg loss: 2.775714 \n",
      "\n",
      "3-------------------\n",
      "624 1711.157556772232\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 10.9%, Avg loss: 2.698771 \n",
      "\n",
      "4-------------------\n",
      "624 1666.0503273010254\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 11.2%, Avg loss: 2.630455 \n",
      "\n",
      "5-------------------\n",
      "624 1626.932178735733\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 11.3%, Avg loss: 2.570249 \n",
      "\n",
      "6-------------------\n",
      "624 1591.9929692745209\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 11.6%, Avg loss: 2.519184 \n",
      "\n",
      "7-------------------\n",
      "624 1561.4862053394318\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 11.9%, Avg loss: 2.473280 \n",
      "\n",
      "8-------------------\n",
      "624 1536.3784084320068\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 12.0%, Avg loss: 2.439217 \n",
      "\n",
      "9-------------------\n",
      "624 1516.9335536956787\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 11.9%, Avg loss: 2.412228 \n",
      "\n",
      "Le taux de learning est de 1e-08\n",
      "0-------------------\n",
      "624 2151.7912242412567\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 9.9%, Avg loss: 3.415959 \n",
      "\n",
      "1-------------------\n",
      "624 2123.247552871704\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 9.8%, Avg loss: 3.370545 \n",
      "\n",
      "2-------------------\n",
      "624 2096.1724038124084\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 9.7%, Avg loss: 3.327932 \n",
      "\n",
      "3-------------------\n",
      "624 2070.441126346588\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 9.7%, Avg loss: 3.291962 \n",
      "\n",
      "4-------------------\n",
      "624 2045.9685487747192\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 9.7%, Avg loss: 3.248218 \n",
      "\n",
      "5-------------------\n",
      "624 2022.6299986839294\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 9.6%, Avg loss: 3.210759 \n",
      "\n",
      "6-------------------\n",
      "624 2000.4178550243378\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 9.6%, Avg loss: 3.178619 \n",
      "\n",
      "7-------------------\n",
      "624 1979.2087333202362\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 9.6%, Avg loss: 3.144964 \n",
      "\n",
      "8-------------------\n",
      "624 1959.0480935573578\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 9.7%, Avg loss: 3.117129 \n",
      "\n",
      "9-------------------\n",
      "624 1939.9065098762512\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 9.8%, Avg loss: 3.085424 \n",
      "\n",
      "Le taux de learning est de 1e-09\n",
      "0-------------------\n",
      "624 2165.0483870506287\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 9.9%, Avg loss: 3.457766 \n",
      "\n",
      "1-------------------\n",
      "624 2161.938536643982\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 9.9%, Avg loss: 3.451720 \n",
      "\n",
      "2-------------------\n",
      "624 2158.8822660446167\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 9.9%, Avg loss: 3.446442 \n",
      "\n",
      "3-------------------\n",
      "624 2155.777284860611\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 9.9%, Avg loss: 3.445983 \n",
      "\n",
      "4-------------------\n",
      "624 2152.784168481827\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 9.9%, Avg loss: 3.434751 \n",
      "\n",
      "5-------------------\n",
      "624 2149.794991016388\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 9.9%, Avg loss: 3.429157 \n",
      "\n",
      "6-------------------\n",
      "624 2146.79967212677\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 9.9%, Avg loss: 3.427371 \n",
      "\n",
      "7-------------------\n",
      "624 2143.8975195884705\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 9.9%, Avg loss: 3.421599 \n",
      "\n",
      "8-------------------\n",
      "624 2140.935198545456\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 9.9%, Avg loss: 3.421503 \n",
      "\n",
      "9-------------------\n",
      "624 2138.021696805954\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 9.9%, Avg loss: 3.413610 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "[0.001,0.0001, 1e-5,  1e-6 ,1e-7, 1e-8,  1e-9]\n",
    "\n",
    "lr_rate_opt = fonction_renvoie_lr_rate(list_learning_rate =list_learning_rate,\\\n",
    "                         device = device, modele = MLP5, train = train,\\\n",
    "                         val = val, number_class = len(id2class), loss_fn=loss_fn)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "47017746-e193-47f3-b11b-d5c657487837",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "47017746-e193-47f3-b11b-d5c657487837",
    "outputId": "3c56ba01-e306-41ae-a923-b46147f28297"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The learning rate is 0.0001\n"
     ]
    }
   ],
   "source": [
    "print(f\"The learning rate is {lr_rate_opt}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0fa570-746e-44dd-8d07-d8b43075fda7",
   "metadata": {},
   "source": [
    "# Now we can use the optimal learning rate in the data test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "bea2d971-023f-416c-8050-7cea11b8bcf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0-------------------\n",
      "624 1327.8958134651184\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 26.5%, Avg loss: 2.025335 \n",
      "\n",
      "1-------------------\n",
      "624 1241.5879427194595\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 29.4%, Avg loss: 1.960112 \n",
      "\n",
      "2-------------------\n",
      "624 1204.2130961418152\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 32.2%, Avg loss: 1.903934 \n",
      "\n",
      "3-------------------\n",
      "624 1179.5019606351852\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 32.4%, Avg loss: 1.895991 \n",
      "\n",
      "4-------------------\n",
      "624 1163.8491501808167\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 34.1%, Avg loss: 1.859964 \n",
      "\n",
      "5-------------------\n",
      "624 1150.017021894455\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 33.6%, Avg loss: 1.846438 \n",
      "\n",
      "6-------------------\n",
      "624 1139.9697340726852\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 33.6%, Avg loss: 1.846604 \n",
      "\n",
      "7-------------------\n",
      "624 1129.5699880123138\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 34.5%, Avg loss: 1.829600 \n",
      "\n",
      "8-------------------\n",
      "624 1120.2726575136185\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 35.0%, Avg loss: 1.809432 \n",
      "\n",
      "9-------------------\n",
      "624 1110.9400565624237\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 35.6%, Avg loss: 1.809386 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "modele_MLP = MLP5(len(id2class)).to(device)\n",
    "optimizer = torch.optim.Adam(modele_MLP.parameters(), lr= lr_rate_opt )\n",
    "\n",
    "torch.manual_seed(133)\n",
    "for epoch in range(10):\n",
    "    print(str(epoch)+\"-------------------\")\n",
    "    train_loop(dataloader=train,optimizer=optimizer,loss_fn=loss_fn,modele=modele_MLP,device=device)\n",
    "    evaluate_loop(dataloader=test,loss_fn=loss_fn,model=modele_MLP,device=device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01758752-10ad-41ff-a9ae-3670408e291c",
   "metadata": {
    "id": "01758752-10ad-41ff-a9ae-3670408e291c"
   },
   "source": [
    "## Exercise 8\n",
    "Write a Python class `MLP5BN` similarly to `MLP5`, but put a batch normalization layer (`torch.nn.BatchNorm1d`) before every activation layer.\n",
    "Then, create an object using your class and keep it in the `modelMLP5BN` variable. Train this model and compare the results for `modelMLP5` and `modelMLP5BN`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "69335fbf-f63f-478f-a39d-9ead47588ec1",
   "metadata": {
    "id": "69335fbf-f63f-478f-a39d-9ead47588ec1",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class MLP5BN(nn.Module):\n",
    "    def __init__(self,nombre_classes):\n",
    "        super().__init__()\n",
    "        self.transform1=nn.Sequential(nn.Flatten(),nn.Linear(32*32,64),torch.nn.BatchNorm1d(64),nn.ReLU())\n",
    "        self.transform2=nn.Sequential(nn.Linear(64,64),torch.nn.BatchNorm1d(64),nn.ReLU())\n",
    "        self.transform3=nn.Linear(64,nombre_classes)\n",
    "    def forward(self,x):\n",
    "        out=self.transform1(x)\n",
    "        out=self.transform2(out)\n",
    "        out=self.transform2(out)\n",
    "        out=self.transform2(out)\n",
    "        out=self.transform3(out)\n",
    "        return(out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea90631-c07c-4a5c-8a99-0400686c3a3a",
   "metadata": {},
   "source": [
    "# Training of the MLP5BN model with learning rate =  1e-7 chosen randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "996702a8-d9cd-4499-93fe-ac14a69993c9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "996702a8-d9cd-4499-93fe-ac14a69993c9",
    "outputId": "538d885c-2deb-43f7-9ee0-8a0fea1b72f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0-------------------\n",
      "624 1481.614773273468\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 9.2%, Avg loss: 2.363973 \n",
      "\n",
      "1-------------------\n",
      "624 1479.897920846939\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 9.3%, Avg loss: 2.367029 \n",
      "\n",
      "2-------------------\n",
      "624 1478.7803642749786\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 9.4%, Avg loss: 2.364260 \n",
      "\n",
      "3-------------------\n",
      "624 1477.328325510025\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 9.4%, Avg loss: 2.357314 \n",
      "\n",
      "4-------------------\n",
      "624 1476.0908031463623\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 9.3%, Avg loss: 2.360965 \n",
      "\n",
      "5-------------------\n",
      "624 1474.495199918747\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 9.5%, Avg loss: 2.354854 \n",
      "\n",
      "6-------------------\n",
      "624 1472.9989593029022\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 9.4%, Avg loss: 2.355109 \n",
      "\n",
      "7-------------------\n",
      "624 1471.7932319641113\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 9.6%, Avg loss: 2.351845 \n",
      "\n",
      "8-------------------\n",
      "624 1470.6771488189697\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 9.7%, Avg loss: 2.348956 \n",
      "\n",
      "9-------------------\n",
      "624 1468.3870875835419\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 9.7%, Avg loss: 2.347931 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "modele_MLP5BN = MLP5BN(len(id2class)).to(device)\n",
    "optimizer2 = torch.optim.Adam(modele_MLP5BN.parameters(), lr = learningRate)\n",
    "for epoch in range(0,10):\n",
    "    print(str(epoch)+\"-------------------\")\n",
    "    train_loop(dataloader=train,optimizer=optimizer2,loss_fn=loss_fn,modele=modele_MLP5BN,device=device)\n",
    "    evaluate_loop(dataloader=test,loss_fn=loss_fn,model=modele_MLP5BN,device=device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7fe80e8-7778-44b7-9aa4-0e0b5958cb1c",
   "metadata": {},
   "source": [
    "# Turning of the MLP5BN model¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "d37d04bb-ea53-4c31-b21c-b55ffbeb39e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le taux de learning est de 0.001\n",
      "0-------------------\n",
      "624 1191.1037833690643\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 33.1%, Avg loss: 1.866882 \n",
      "\n",
      "1-------------------\n",
      "624 1093.9910589456558\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 34.0%, Avg loss: 1.843195 \n",
      "\n",
      "2-------------------\n",
      "624 1048.5422142744064\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 35.8%, Avg loss: 1.826039 \n",
      "\n",
      "3-------------------\n",
      "624 1017.2776210308075\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 36.4%, Avg loss: 1.796260 \n",
      "\n",
      "4-------------------\n",
      "624 994.7967553138733\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 38.5%, Avg loss: 1.734519 \n",
      "\n",
      "5-------------------\n",
      "624 972.2741770744324\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 38.9%, Avg loss: 1.745616 \n",
      "\n",
      "6-------------------\n",
      "624 960.1634880304337\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 37.7%, Avg loss: 1.783462 \n",
      "\n",
      "7-------------------\n",
      "624 943.6140244007111\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 40.7%, Avg loss: 1.682287 \n",
      "\n",
      "8-------------------\n",
      "624 930.5562771558762\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 37.2%, Avg loss: 1.791320 \n",
      "\n",
      "9-------------------\n",
      "624 917.3188965320587\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 40.0%, Avg loss: 1.748191 \n",
      "\n",
      "Le taux de learning est de 0.0001\n",
      "0-------------------\n",
      "624 1312.5662719011307\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 30.8%, Avg loss: 1.982392 \n",
      "\n",
      "1-------------------\n",
      "624 1190.972941994667\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 33.0%, Avg loss: 1.879564 \n",
      "\n",
      "2-------------------\n",
      "624 1136.0560450553894\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 34.4%, Avg loss: 1.848907 \n",
      "\n",
      "3-------------------\n",
      "624 1099.8550375699997\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 35.8%, Avg loss: 1.790108 \n",
      "\n",
      "4-------------------\n",
      "624 1070.3680222034454\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 36.2%, Avg loss: 1.777868 \n",
      "\n",
      "5-------------------\n",
      "624 1046.6462808847427\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 37.4%, Avg loss: 1.756322 \n",
      "\n",
      "6-------------------\n",
      "624 1029.4942654371262\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 37.5%, Avg loss: 1.755618 \n",
      "\n",
      "7-------------------\n",
      "624 1011.8229795694351\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 37.7%, Avg loss: 1.735558 \n",
      "\n",
      "8-------------------\n",
      "624 997.1456654071808\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 37.3%, Avg loss: 1.756635 \n",
      "\n",
      "9-------------------\n",
      "624 985.1993323564529\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 37.5%, Avg loss: 1.750644 \n",
      "\n",
      "Le taux de learning est de 1e-05\n",
      "0-------------------\n",
      "624 1433.4401366710663\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 16.7%, Avg loss: 2.239812 \n",
      "\n",
      "1-------------------\n",
      "624 1377.184962272644\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 21.3%, Avg loss: 2.183646 \n",
      "\n",
      "2-------------------\n",
      "624 1343.7050359249115\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 24.9%, Avg loss: 2.135840 \n",
      "\n",
      "3-------------------\n",
      "624 1317.2684977054596\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 26.8%, Avg loss: 2.096785 \n",
      "\n",
      "4-------------------\n",
      "624 1293.8657252788544\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 29.0%, Avg loss: 2.061338 \n",
      "\n",
      "5-------------------\n",
      "624 1274.672155380249\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 29.9%, Avg loss: 2.038187 \n",
      "\n",
      "6-------------------\n",
      "624 1258.3048759698868\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 30.5%, Avg loss: 2.017967 \n",
      "\n",
      "7-------------------\n",
      "624 1243.3537428379059\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 31.2%, Avg loss: 1.994625 \n",
      "\n",
      "8-------------------\n",
      "624 1230.0841443538666\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 31.7%, Avg loss: 1.972892 \n",
      "\n",
      "9-------------------\n",
      "624 1218.7375836372375\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 32.0%, Avg loss: 1.959830 \n",
      "\n",
      "Le taux de learning est de 1e-06\n",
      "0-------------------\n",
      "624 1475.5227653980255\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 10.5%, Avg loss: 2.339752 \n",
      "\n",
      "1-------------------\n",
      "624 1461.9869666099548\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 11.1%, Avg loss: 2.328600 \n",
      "\n",
      "2-------------------\n",
      "624 1450.605835199356\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 12.1%, Avg loss: 2.309301 \n",
      "\n",
      "3-------------------\n",
      "624 1440.0963389873505\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 13.3%, Avg loss: 2.300390 \n",
      "\n",
      "4-------------------\n",
      "624 1430.8923556804657\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 13.9%, Avg loss: 2.287868 \n",
      "\n",
      "5-------------------\n",
      "624 1422.6776285171509\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 14.9%, Avg loss: 2.273346 \n",
      "\n",
      "6-------------------\n",
      "624 1415.3754034042358\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 15.4%, Avg loss: 2.265903 \n",
      "\n",
      "7-------------------\n",
      "624 1408.7854890823364\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 15.8%, Avg loss: 2.255696 \n",
      "\n",
      "8-------------------\n",
      "624 1403.6556360721588\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 16.5%, Avg loss: 2.245860 \n",
      "\n",
      "9-------------------\n",
      "624 1397.2250761985779\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 17.1%, Avg loss: 2.239396 \n",
      "\n",
      "Le taux de learning est de 1e-07\n",
      "0-------------------\n",
      "624 1482.0558907985687\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 9.6%, Avg loss: 2.356216 \n",
      "\n",
      "1-------------------\n",
      "624 1480.8913385868073\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 9.2%, Avg loss: 2.360331 \n",
      "\n",
      "2-------------------\n",
      "624 1479.8026123046875\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 9.6%, Avg loss: 2.354534 \n",
      "\n",
      "3-------------------\n",
      "624 1477.822762966156\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 9.4%, Avg loss: 2.360248 \n",
      "\n",
      "4-------------------\n",
      "624 1476.0195457935333\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 9.8%, Avg loss: 2.356410 \n",
      "\n",
      "5-------------------\n",
      "624 1474.7637598514557\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 9.8%, Avg loss: 2.349389 \n",
      "\n",
      "6-------------------\n",
      "624 1472.8481438159943\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 9.9%, Avg loss: 2.352656 \n",
      "\n",
      "7-------------------\n",
      "624 1471.2941734790802\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 10.1%, Avg loss: 2.346808 \n",
      "\n",
      "8-------------------\n",
      "624 1470.9694316387177\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 10.2%, Avg loss: 2.346604 \n",
      "\n",
      "9-------------------\n",
      "624 1468.6526584625244\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 10.2%, Avg loss: 2.346428 \n",
      "\n",
      "Le taux de learning est de 1e-08\n",
      "0-------------------\n",
      "624 1482.7283685207367\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 9.5%, Avg loss: 2.357993 \n",
      "\n",
      "1-------------------\n",
      "624 1482.9463438987732\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 9.0%, Avg loss: 2.363887 \n",
      "\n",
      "2-------------------\n",
      "624 1483.2193059921265\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 9.3%, Avg loss: 2.359842 \n",
      "\n",
      "3-------------------\n",
      "624 1482.4017193317413\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 9.3%, Avg loss: 2.367563 \n",
      "\n",
      "4-------------------\n",
      "624 1481.973546743393\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 9.4%, Avg loss: 2.365367 \n",
      "\n",
      "5-------------------\n",
      "624 1481.964435338974\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 9.2%, Avg loss: 2.360090 \n",
      "\n",
      "6-------------------\n",
      "624 1481.3751039505005\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 9.4%, Avg loss: 2.365503 \n",
      "\n",
      "7-------------------\n",
      "624 1481.1892552375793\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 9.3%, Avg loss: 2.360480 \n",
      "\n",
      "8-------------------\n",
      "624 1482.0415105819702\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 9.4%, Avg loss: 2.362632 \n",
      "\n",
      "9-------------------\n",
      "624 1480.8710644245148\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 9.3%, Avg loss: 2.363573 \n",
      "\n",
      "Le taux de learning est de 1e-09\n",
      "0-------------------\n",
      "624 1482.7998626232147\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 9.5%, Avg loss: 2.358184 \n",
      "\n",
      "1-------------------\n",
      "624 1483.1659734249115\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 8.9%, Avg loss: 2.364268 \n",
      "\n",
      "2-------------------\n",
      "624 1483.5876195430756\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 9.3%, Avg loss: 2.360410 \n",
      "\n",
      "3-------------------\n",
      "624 1482.9027390480042\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 9.2%, Avg loss: 2.368370 \n",
      "\n",
      "4-------------------\n",
      "624 1482.6290814876556\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 9.4%, Avg loss: 2.366341 \n",
      "\n",
      "5-------------------\n",
      "624 1482.7610037326813\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 9.2%, Avg loss: 2.361269 \n",
      "\n",
      "6-------------------\n",
      "624 1482.3289771080017\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 9.4%, Avg loss: 2.366914 \n",
      "\n",
      "7-------------------\n",
      "624 1482.2845799922943\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 9.2%, Avg loss: 2.361997 \n",
      "\n",
      "8-------------------\n",
      "624 1483.2813231945038\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 9.4%, Avg loss: 2.364412 \n",
      "\n",
      "9-------------------\n",
      "624 1482.2437801361084\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 9.3%, Avg loss: 2.365498 \n",
      "\n",
      "0.001\n"
     ]
    }
   ],
   "source": [
    "list_learning_rate = [0.001,0.0001, 1e-5,  1e-6 ,1e-7, 1e-8,  1e-9]\n",
    "lr_rate_opt = fonction_renvoie_lr_rate(list_learning_rate =list_learning_rate,\\\n",
    "                                       device = device, modele = MLP5BN, train = train,\\\n",
    "                                       val = val, number_class = len(id2class), loss_fn=loss_fn)\n",
    "print(lr_rate_opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b88a807-8802-4afa-b17d-a669bf9c0e50",
   "metadata": {},
   "source": [
    "# Now we can use the optimal learning rate in the data test and compare with last model after compute the number of parameter of each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "4808f074-90e3-4fc4-937a-76cf7dbacef2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4808f074-90e3-4fc4-937a-76cf7dbacef2",
    "outputId": "7b05fecd-5a3a-47b8-a25a-4ee7edbcb42d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The learning rate is 0.001\n",
      "The number of the parameter for the MLP model is 70410.\n",
      "The number of parameter for  MLP5BN model is 70666.\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "dde285f3-4bca-4fe9-8cc9-34cfd748ffad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0-------------------\n",
      "624 1190.751358628273\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 34.7%, Avg loss: 1.835258 \n",
      "\n",
      "1-------------------\n",
      "624 1091.2581280469894\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 35.9%, Avg loss: 1.824693 \n",
      "\n",
      "2-------------------\n",
      "624 1044.7556145191193\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 37.6%, Avg loss: 1.777497 \n",
      "\n",
      "3-------------------\n",
      "624 1016.5057243108749\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 37.7%, Avg loss: 1.734640 \n",
      "\n",
      "4-------------------\n",
      "624 990.8377208709717\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 36.7%, Avg loss: 1.816229 \n",
      "\n",
      "5-------------------\n",
      "624 969.37724173069\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 39.4%, Avg loss: 1.732337 \n",
      "\n",
      "6-------------------\n",
      "624 956.6891151666641\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 38.9%, Avg loss: 1.741388 \n",
      "\n",
      "7-------------------\n",
      "624 939.4556224346161\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 38.8%, Avg loss: 1.732700 \n",
      "\n",
      "8-------------------\n",
      "624 926.7071242332458\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 39.1%, Avg loss: 1.761387 \n",
      "\n",
      "9-------------------\n",
      "624 914.6457483768463\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 39.9%, Avg loss: 1.738335 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "modele_MLP5BN = MLP5BN(len(id2class)).to(device)\n",
    "optimizer2 = torch.optim.Adam(modele_MLP5BN.parameters(), lr = lr_rate_opt)\n",
    "torch.manual_seed(133)\n",
    "for epoch in range(0,10):\n",
    "    print(str(epoch)+\"-------------------\")\n",
    "    train_loop(dataloader=train,optimizer=optimizer2,loss_fn=loss_fn,modele=modele_MLP5BN,device=device)\n",
    "    evaluate_loop(dataloader=test,loss_fn=loss_fn,model=modele_MLP5BN,device=device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "65a85742-4da7-4831-9ad8-3ef1c0d4107c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The learning rate is 0.001\n",
      "The number of the parameter for the MLP model is 70410.\n",
      "The number of parameter for  MLP5BN model is 70666.\n",
      "The accuracy of the MLP5BN model is greater than the accuracy of MLP. But the MLP model have less parameters\n"
     ]
    }
   ],
   "source": [
    "print(f\"The learning rate is {lr_rate_opt}\")\n",
    "total_params_mlp = sum(p.numel() for p in modele_MLP.parameters())\n",
    "print(f'The number of the parameter for the MLP model is {total_params_mlp}.')\n",
    "total_params_mlp5B=sum(p.numel() for p in modele_MLP5BN.parameters())\n",
    "print(f'The number of parameter for  MLP5BN model is {total_params_mlp5B}.')\n",
    "print(f\"The accuracy of the MLP5BN model is greater than the accuracy of MLP. But the MLP model have less parameters\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4b9bf7-aef8-41d2-badd-98f4f55f6f9c",
   "metadata": {
    "id": "df4b9bf7-aef8-41d2-badd-98f4f55f6f9c"
   },
   "source": [
    "## Exercise 9\n",
    "The following Python class `LeNet5` is an implementation of a Convolutional Neural Network (CNN).\n",
    "Train this model and compare it with the previous two models. (Ignore the `num_channels` parameter of the class for now. Set it to the default value `1`.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "fd362515-d777-450b-91f2-9bdb8933dfaf",
   "metadata": {
    "id": "fd362515-d777-450b-91f2-9bdb8933dfaf",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class LeNet5(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(LeNet5, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 6, kernel_size=5, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(6),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(6, 16, kernel_size=5, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc = nn.Linear(400, 120)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc1 = nn.Linear(120, 84)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(84, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)  # Second dimension is for channels, but we only have one channel.\n",
    "        out = self.layer2(out)\n",
    "        out = self.flatten(out)\n",
    "        out = self.fc(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc1(out)\n",
    "        out = self.relu1(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99214525-b829-42eb-9046-7de388f10836",
   "metadata": {},
   "source": [
    "# Turning of the model for finding the best learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "967c62ef-ad7a-41ca-8dfc-ae29af50254e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le taux de learning est de 0.001\n",
      "0-------------------\n",
      "624 1020.2815741300583\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 45.0%, Avg loss: 1.539438 \n",
      "\n",
      "1-------------------\n",
      "624 833.0035327672958\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 47.6%, Avg loss: 1.480780 \n",
      "\n",
      "2-------------------\n",
      "624 763.3685903549194\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 57.7%, Avg loss: 1.204859 \n",
      "\n",
      "3-------------------\n",
      "624 716.9421616196632\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 55.2%, Avg loss: 1.297058 \n",
      "\n",
      "4-------------------\n",
      "624 682.7672057151794\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 58.4%, Avg loss: 1.200230 \n",
      "\n",
      "5-------------------\n",
      "624 649.2964463829994\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 57.6%, Avg loss: 1.208298 \n",
      "\n",
      "6-------------------\n",
      "624 628.0925893187523\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 57.0%, Avg loss: 1.253380 \n",
      "\n",
      "7-------------------\n",
      "624 602.2908146977425\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 59.4%, Avg loss: 1.182074 \n",
      "\n",
      "8-------------------\n",
      "624 580.5943481326103\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 61.5%, Avg loss: 1.121503 \n",
      "\n",
      "9-------------------\n",
      "624 560.6553441882133\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 61.9%, Avg loss: 1.125660 \n",
      "\n",
      "Le taux de learning est de 0.0001\n",
      "0-------------------\n",
      "624 1218.9694610834122\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 37.6%, Avg loss: 1.736397 \n",
      "\n",
      "1-------------------\n",
      "624 1021.8981951475143\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 42.2%, Avg loss: 1.616385 \n",
      "\n",
      "2-------------------\n",
      "624 963.5816048383713\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 45.7%, Avg loss: 1.535633 \n",
      "\n",
      "3-------------------\n",
      "624 923.7445545196533\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 47.3%, Avg loss: 1.488346 \n",
      "\n",
      "4-------------------\n",
      "624 891.4198368787766\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 49.0%, Avg loss: 1.447700 \n",
      "\n",
      "5-------------------\n",
      "624 862.0549491643906\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 51.2%, Avg loss: 1.399915 \n",
      "\n",
      "6-------------------\n",
      "624 840.7540512084961\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 50.5%, Avg loss: 1.422627 \n",
      "\n",
      "7-------------------\n",
      "624 822.0220014452934\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 53.2%, Avg loss: 1.343452 \n",
      "\n",
      "8-------------------\n",
      "624 805.8103886842728\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 53.5%, Avg loss: 1.349738 \n",
      "\n",
      "9-------------------\n",
      "624 791.5108290910721\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 54.3%, Avg loss: 1.311428 \n",
      "\n",
      "Le taux de learning est de 1e-05\n",
      "0-------------------\n",
      "624 1425.9793665409088\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 16.4%, Avg loss: 2.252271 \n",
      "\n",
      "1-------------------\n",
      "624 1376.958795785904\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 24.0%, Avg loss: 2.150616 \n",
      "\n",
      "2-------------------\n",
      "624 1305.4072020053864\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 27.3%, Avg loss: 2.038018 \n",
      "\n",
      "3-------------------\n",
      "624 1242.773696422577\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 29.6%, Avg loss: 1.955352 \n",
      "\n",
      "4-------------------\n",
      "624 1196.7184824943542\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 32.1%, Avg loss: 1.891837 \n",
      "\n",
      "5-------------------\n",
      "624 1161.7369803190231\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 34.0%, Avg loss: 1.843838 \n",
      "\n",
      "6-------------------\n",
      "624 1132.801780462265\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 35.5%, Avg loss: 1.802349 \n",
      "\n",
      "7-------------------\n",
      "624 1109.0618327856064\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 36.5%, Avg loss: 1.767314 \n",
      "\n",
      "8-------------------\n",
      "624 1089.799440741539\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 37.3%, Avg loss: 1.740310 \n",
      "\n",
      "9-------------------\n",
      "624 1073.8053232431412\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 38.2%, Avg loss: 1.718037 \n",
      "\n",
      "Le taux de learning est de 1e-06\n",
      "0-------------------\n",
      "624 1442.219715833664\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 10.2%, Avg loss: 2.305212 \n",
      "\n",
      "1-------------------\n",
      "624 1438.0601360797882\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 10.6%, Avg loss: 2.299448 \n",
      "\n",
      "2-------------------\n",
      "624 1434.5445811748505\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 11.3%, Avg loss: 2.294453 \n",
      "\n",
      "3-------------------\n",
      "624 1431.187959909439\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 11.8%, Avg loss: 2.289085 \n",
      "\n",
      "4-------------------\n",
      "624 1427.8701665401459\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 12.4%, Avg loss: 2.283886 \n",
      "\n",
      "5-------------------\n",
      "624 1424.4501757621765\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 13.2%, Avg loss: 2.278811 \n",
      "\n",
      "6-------------------\n",
      "624 1420.9177556037903\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 13.9%, Avg loss: 2.272687 \n",
      "\n",
      "7-------------------\n",
      "624 1417.173513174057\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 14.6%, Avg loss: 2.266678 \n",
      "\n",
      "8-------------------\n",
      "624 1413.2971551418304\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 15.3%, Avg loss: 2.260503 \n",
      "\n",
      "9-------------------\n",
      "624 1409.1978752613068\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 16.2%, Avg loss: 2.254230 \n",
      "\n",
      "Le taux de learning est de 1e-07\n",
      "0-------------------\n",
      "624 1444.3742475509644\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 10.0%, Avg loss: 2.311584 \n",
      "\n",
      "1-------------------\n",
      "624 1443.8732070922852\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 10.1%, Avg loss: 2.311027 \n",
      "\n",
      "2-------------------\n",
      "624 1443.3880815505981\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 10.1%, Avg loss: 2.310388 \n",
      "\n",
      "3-------------------\n",
      "624 1442.8507947921753\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 10.2%, Avg loss: 2.309581 \n",
      "\n",
      "4-------------------\n",
      "624 1442.3771102428436\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 10.2%, Avg loss: 2.309003 \n",
      "\n",
      "5-------------------\n",
      "624 1441.943782567978\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 10.2%, Avg loss: 2.308473 \n",
      "\n",
      "6-------------------\n",
      "624 1441.481199979782\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 10.2%, Avg loss: 2.307409 \n",
      "\n",
      "7-------------------\n",
      "624 1441.0300707817078\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 10.2%, Avg loss: 2.306895 \n",
      "\n",
      "8-------------------\n",
      "624 1440.6011180877686\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 10.2%, Avg loss: 2.306084 \n",
      "\n",
      "9-------------------\n",
      "624 1440.1565654277802\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 10.2%, Avg loss: 2.305470 \n",
      "\n",
      "Le taux de learning est de 1e-08\n",
      "0-------------------\n",
      "624 1444.6103479862213\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 10.0%, Avg loss: 2.312312 \n",
      "\n",
      "1-------------------\n",
      "624 1444.5793724060059\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 10.0%, Avg loss: 2.312483 \n",
      "\n",
      "2-------------------\n",
      "624 1444.5435626506805\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 10.0%, Avg loss: 2.312521 \n",
      "\n",
      "3-------------------\n",
      "624 1444.4409272670746\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 10.0%, Avg loss: 2.312402 \n",
      "\n",
      "4-------------------\n",
      "624 1444.3881812095642\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 10.0%, Avg loss: 2.312500 \n",
      "\n",
      "5-------------------\n",
      "624 1444.3647074699402\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 10.0%, Avg loss: 2.312559 \n",
      "\n",
      "6-------------------\n",
      "624 1444.301057100296\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 10.0%, Avg loss: 2.312123 \n",
      "\n",
      "7-------------------\n",
      "624 1444.241189956665\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 10.0%, Avg loss: 2.312235 \n",
      "\n",
      "8-------------------\n",
      "624 1444.1861793994904\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 10.0%, Avg loss: 2.311985 \n",
      "\n",
      "9-------------------\n",
      "624 1444.114117383957\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 10.0%, Avg loss: 2.311897 \n",
      "\n",
      "Le taux de learning est de 1e-09\n",
      "0-------------------\n",
      "624 1444.6360530853271\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 10.0%, Avg loss: 2.312392 \n",
      "\n",
      "1-------------------\n",
      "624 1444.6571168899536\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 10.0%, Avg loss: 2.312645 \n",
      "\n",
      "2-------------------\n",
      "624 1444.6728093624115\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 10.0%, Avg loss: 2.312761 \n",
      "\n",
      "3-------------------\n",
      "624 1444.6214773654938\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 10.0%, Avg loss: 2.312725 \n",
      "\n",
      "4-------------------\n",
      "624 1444.619831085205\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 10.0%, Avg loss: 2.312906 \n",
      "\n",
      "5-------------------\n",
      "624 1444.647498846054\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 10.0%, Avg loss: 2.313037 \n",
      "\n",
      "6-------------------\n",
      "624 1444.6345047950745\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 10.0%, Avg loss: 2.312683 \n",
      "\n",
      "7-------------------\n",
      "624 1444.6263420581818\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 10.0%, Avg loss: 2.312879 \n",
      "\n",
      "8-------------------\n",
      "624 1444.620712518692\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 10.0%, Avg loss: 2.312704 \n",
      "\n",
      "9-------------------\n",
      "624 1444.5998322963715\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 10.0%, Avg loss: 2.312688 \n",
      "\n",
      "0.001\n"
     ]
    }
   ],
   "source": [
    "list_learning_rate = [0.001,0.0001, 1e-5,  1e-6 ,1e-7, 1e-8,  1e-9]\n",
    "\n",
    "lr_rate_opt = fonction_renvoie_lr_rate(list_learning_rate =list_learning_rate,\\\n",
    "                                       device = device, modele = LeNet5, train = train,\\\n",
    "                                       val = val, number_class = len(id2class), loss_fn=loss_fn)\n",
    "print(lr_rate_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "522d6194-11e9-43a1-b350-348dd30c1f59",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "522d6194-11e9-43a1-b350-348dd30c1f59",
    "outputId": "9fc5f2ea-e1a1-4355-ddb3-e0fa9827c5b6",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0-------------------\n",
      "624 1020.2815741300583\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 44.8%, Avg loss: 1.529709 \n",
      "\n",
      "1-------------------\n",
      "624 833.0035327672958\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 48.8%, Avg loss: 1.473985 \n",
      "\n",
      "2-------------------\n",
      "624 763.3685903549194\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 57.4%, Avg loss: 1.201727 \n",
      "\n",
      "3-------------------\n",
      "624 716.9421616196632\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 55.1%, Avg loss: 1.290520 \n",
      "\n",
      "4-------------------\n",
      "624 682.7672057151794\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 58.1%, Avg loss: 1.196384 \n",
      "\n",
      "5-------------------\n",
      "624 649.2964463829994\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 58.4%, Avg loss: 1.197956 \n",
      "\n",
      "6-------------------\n",
      "624 628.0925893187523\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 57.0%, Avg loss: 1.259965 \n",
      "\n",
      "7-------------------\n",
      "624 602.2908146977425\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 59.9%, Avg loss: 1.173707 \n",
      "\n",
      "8-------------------\n",
      "624 580.5943481326103\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 61.6%, Avg loss: 1.113328 \n",
      "\n",
      "9-------------------\n",
      "624 560.6553441882133\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 62.7%, Avg loss: 1.116382 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "reseau_cnn = LeNet5().to(device)\n",
    "\n",
    "optimizercnn = torch.optim.Adam(reseau_cnn.parameters(), lr = lr_rate_opt)\n",
    "\n",
    "torch.manual_seed(133)\n",
    "\n",
    "for epoch in range(0,10):\n",
    "    print(str(epoch)+\"-------------------\")\n",
    "    train_loop(dataloader=train,optimizer=optimizercnn,loss_fn=loss_fn,modele=reseau_cnn,device=device)\n",
    "    evaluate_loop(dataloader=test,loss_fn=loss_fn,model=reseau_cnn,device=device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0733d3f8-febd-4419-b3f0-ae995dc069b7",
   "metadata": {},
   "source": [
    "# Comparison with the previous models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "fec753c3-8e6c-494c-b33e-4e624e347c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of parameter for  MLP5BN model is 61750.\n",
      "It is best model with accuracy close to 62% with the fewest parameters\n"
     ]
    }
   ],
   "source": [
    "total_params_reseau_cnn=sum(p.numel() for p in reseau_cnn.parameters())\n",
    "print(f'The number of parameter for  MLP5BN model is {total_params_reseau_cnn}.')\n",
    "print(\"It is best model with accuracy close to 62% with the fewest parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b5f75c-79c9-4058-995c-c73d176ab7f8",
   "metadata": {
    "id": "87b5f75c-79c9-4058-995c-c73d176ab7f8"
   },
   "source": [
    "## Exercise 10\n",
    "Below is the same dataset but with colors. For expressing the intensities for the red, green, blue colors, each image has 3 *channels* now, which is why the shape of each image is `(3, 32, 32)`.\n",
    "The goal of this exercise is to train a classifier using `LeNet5`, but the `LeNet5` class defined above assumes that input images have only one channel, so we need to rewrite the class a bit. For that, read [the documentation for `torch.nn.Conv2d` class](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html?highlight=conv2d#torch.nn.Conv2d) to understand how to modify the first layer of the `LeNet5` class. Write code for this modified class, naming it `LeNet5Color`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "71796fb0-1f80-4a5c-9753-4648c48ad3ad",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 222
    },
    "id": "71796fb0-1f80-4a5c-9753-4648c48ad3ad",
    "outputId": "c2bdb346-c4cc-4b6c-f0e3-1912abd84f94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "['truck', 'truck', 'deer', 'automobile', 'automobile']\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x200 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of an image: (3, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "x_train_val_np_color, y_train_val_np_color = load_cifar10(train=True, color=True)\n",
    "x_test_np_color, y_test_np_color = load_cifar10(train=False, color=True)\n",
    "plot_images(x_train_val_np_color, y_train_val_np_color, rows=1, cols=5, color=True)\n",
    "print(f'Shape of an image: {x_train_val_np_color[0].shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "2c1aa3d8-0d79-4747-828c-7ac91393712e",
   "metadata": {
    "id": "2c1aa3d8-0d79-4747-828c-7ac91393712e"
   },
   "outputs": [],
   "source": [
    "class LeNet5Color(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(LeNet5Color, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=6, kernel_size=5, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(6),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(6, 16, kernel_size=5, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc = nn.Linear(400, 120)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc1 = nn.Linear(120, 84)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(84, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)  # Second dimension is for channels, but we only have one channel.\n",
    "        out = self.layer2(out)\n",
    "        out = self.flatten(out)\n",
    "        out = self.fc(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc1(out)\n",
    "        out = self.relu1(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd0acd0-b720-41e2-a6e4-0e7ac13070a1",
   "metadata": {
    "id": "6cd0acd0-b720-41e2-a6e4-0e7ac13070a1"
   },
   "source": [
    "# Exercise 11\n",
    "### Split the data, create dataloaders, train an instance of `LeNet5Color`, and compare it with `LeNet5` using the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "70673a87-abb2-4414-9c08-7aaf1c4a49cf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "70673a87-abb2-4414-9c08-7aaf1c4a49cf",
    "outputId": "5856f719-1581-46e4-bff6-a0633dbcdec2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 3, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "x_train_np_color, x_val_np_color, y_train_np_color, y_val_np_color = train_test_split(\n",
    "    x_train_val_np_color, y_train_val_np_color, train_size=40000,\n",
    "    stratify=y_train_val_np_color, random_state=43,\n",
    ")\n",
    "print(x_train_np_color.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "8506fc64-45a1-491d-b6fa-29559c3f50c5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8506fc64-45a1-491d-b6fa-29559c3f50c5",
    "outputId": "daabb16a-31cb-4683-9046-951c9a0fbb58"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "x_train_color = torch.from_numpy(x_train_np_color).to(dtype=torch.float32)\n",
    "y_train_color = torch.from_numpy(y_train_np_color).to(dtype=torch.int64)  # Class labels are usually integers\n",
    "\n",
    "x_val_color = torch.from_numpy(x_val_np_color).to(dtype=torch.float32)\n",
    "y_val_color = torch.from_numpy(y_val_np_color).to(dtype=torch.int64)\n",
    "\n",
    "x_test_color = torch.from_numpy(x_test_np_color).to(dtype=torch.float32)\n",
    "y_test_color = torch.from_numpy(y_test_np_color).to(dtype=torch.int64)\n",
    "print(x_train_color.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "b982a28f-f082-4002-b9c5-b39fa2016b26",
   "metadata": {
    "id": "b982a28f-f082-4002-b9c5-b39fa2016b26"
   },
   "outputs": [],
   "source": [
    "train_color = DataLoader(CustomDataset(x_train_color,y_train_color), batch_size=64, shuffle =True)\n",
    "\n",
    "test_color = DataLoader(CustomDataset(x_test_color,y_test_color), batch_size=64, shuffle =True)\n",
    "\n",
    "val_color = DataLoader(CustomDataset(x_val_color,y_val_color), batch_size=64, shuffle =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "3fa0ba56-47cb-4445-bceb-42c2e7d4e5e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le taux de learning est de 0.001\n",
      "0-------------------\n",
      "624 971.0558356046677\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 50.2%, Avg loss: 1.377291 \n",
      "\n",
      "1-------------------\n",
      "624 810.7250182032585\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 52.5%, Avg loss: 1.330273 \n",
      "\n",
      "2-------------------\n",
      "624 740.5806648135185\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 54.5%, Avg loss: 1.271292 \n",
      "\n",
      "3-------------------\n",
      "624 690.3418020009995\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 58.9%, Avg loss: 1.196456 \n",
      "\n",
      "4-------------------\n",
      "624 649.8410103321075\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 60.5%, Avg loss: 1.122789 \n",
      "\n",
      "5-------------------\n",
      "624 615.1594572067261\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 60.6%, Avg loss: 1.123664 \n",
      "\n",
      "6-------------------\n",
      "624 587.0130043625832\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 61.0%, Avg loss: 1.140039 \n",
      "\n",
      "7-------------------\n",
      "624 565.7222177684307\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 60.8%, Avg loss: 1.128985 \n",
      "\n",
      "8-------------------\n",
      "624 540.3675037026405\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 63.6%, Avg loss: 1.046041 \n",
      "\n",
      "9-------------------\n",
      "624 519.1642889678478\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 61.9%, Avg loss: 1.121374 \n",
      "\n",
      "Le taux de learning est de 0.0001\n",
      "0-------------------\n",
      "624 1164.4841313362122\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 40.6%, Avg loss: 1.633557 \n",
      "\n",
      "1-------------------\n",
      "624 955.7094932794571\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 45.9%, Avg loss: 1.487379 \n",
      "\n",
      "2-------------------\n",
      "624 894.7189676761627\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 48.5%, Avg loss: 1.428607 \n",
      "\n",
      "3-------------------\n",
      "624 861.6402063965797\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 49.9%, Avg loss: 1.395567 \n",
      "\n",
      "4-------------------\n",
      "624 836.1815674901009\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 51.7%, Avg loss: 1.358095 \n",
      "\n",
      "5-------------------\n",
      "624 813.4035853147507\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 53.1%, Avg loss: 1.319642 \n",
      "\n",
      "6-------------------\n",
      "624 797.391892015934\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 53.7%, Avg loss: 1.319281 \n",
      "\n",
      "7-------------------\n",
      "624 781.7776886820793\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 54.8%, Avg loss: 1.287622 \n",
      "\n",
      "8-------------------\n",
      "624 768.3866426348686\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 55.2%, Avg loss: 1.267981 \n",
      "\n",
      "9-------------------\n",
      "624 753.3656667470932\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 55.9%, Avg loss: 1.250842 \n",
      "\n",
      "Le taux de learning est de 1e-05\n",
      "0-------------------\n",
      "624 1421.0353336334229\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 23.1%, Avg loss: 2.221076 \n",
      "\n",
      "1-------------------\n",
      "624 1333.1306754350662\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 30.4%, Avg loss: 2.044543 \n",
      "\n",
      "2-------------------\n",
      "624 1231.9553587436676\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 33.2%, Avg loss: 1.912914 \n",
      "\n",
      "3-------------------\n",
      "624 1166.5903939008713\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 35.0%, Avg loss: 1.834221 \n",
      "\n",
      "4-------------------\n",
      "624 1123.7071437835693\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 36.5%, Avg loss: 1.776066 \n",
      "\n",
      "5-------------------\n",
      "624 1093.3665561676025\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 37.4%, Avg loss: 1.736087 \n",
      "\n",
      "6-------------------\n",
      "624 1069.5563436746597\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 38.6%, Avg loss: 1.703841 \n",
      "\n",
      "7-------------------\n",
      "624 1048.3134599924088\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 39.2%, Avg loss: 1.674377 \n",
      "\n",
      "8-------------------\n",
      "624 1029.145474910736\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 40.4%, Avg loss: 1.646751 \n",
      "\n",
      "9-------------------\n",
      "624 1012.4778537750244\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 41.0%, Avg loss: 1.621272 \n",
      "\n",
      "Le taux de learning est de 1e-06\n",
      "0-------------------\n",
      "624 1443.2270393371582\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 11.1%, Avg loss: 2.305668 \n",
      "\n",
      "1-------------------\n",
      "624 1438.7822797298431\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 12.1%, Avg loss: 2.298760 \n",
      "\n",
      "2-------------------\n",
      "624 1434.4913866519928\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 13.1%, Avg loss: 2.291787 \n",
      "\n",
      "3-------------------\n",
      "624 1430.0331377983093\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 13.9%, Avg loss: 2.284650 \n",
      "\n",
      "4-------------------\n",
      "624 1425.2863628864288\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 14.7%, Avg loss: 2.276637 \n",
      "\n",
      "5-------------------\n",
      "624 1420.136240720749\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 16.0%, Avg loss: 2.268136 \n",
      "\n",
      "6-------------------\n",
      "624 1414.4474458694458\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 17.5%, Avg loss: 2.258727 \n",
      "\n",
      "7-------------------\n",
      "624 1408.2424311637878\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 18.8%, Avg loss: 2.248521 \n",
      "\n",
      "8-------------------\n",
      "624 1401.390117406845\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 20.7%, Avg loss: 2.237888 \n",
      "\n",
      "9-------------------\n",
      "624 1394.1118700504303\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 22.2%, Avg loss: 2.225367 \n",
      "\n",
      "Le taux de learning est de 1e-07\n",
      "0-------------------\n",
      "624 1445.2439687252045\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 10.3%, Avg loss: 2.312014 \n",
      "\n",
      "1-------------------\n",
      "624 1444.7417232990265\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 10.4%, Avg loss: 2.311415 \n",
      "\n",
      "2-------------------\n",
      "624 1444.3387308120728\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 10.4%, Avg loss: 2.310545 \n",
      "\n",
      "3-------------------\n",
      "624 1443.8295502662659\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 10.6%, Avg loss: 2.309880 \n",
      "\n",
      "4-------------------\n",
      "624 1443.4157831668854\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 10.7%, Avg loss: 2.309588 \n",
      "\n",
      "5-------------------\n",
      "624 1442.9754827022552\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 10.8%, Avg loss: 2.308614 \n",
      "\n",
      "6-------------------\n",
      "624 1442.495220899582\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 10.9%, Avg loss: 2.308098 \n",
      "\n",
      "7-------------------\n",
      "624 1442.0751700401306\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 11.0%, Avg loss: 2.307331 \n",
      "\n",
      "8-------------------\n",
      "624 1441.5994801521301\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 11.1%, Avg loss: 2.306424 \n",
      "\n",
      "9-------------------\n",
      "624 1441.1682426929474\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 11.1%, Avg loss: 2.305741 \n",
      "\n",
      "Le taux de learning est de 1e-08\n",
      "0-------------------\n",
      "624 1445.4503817558289\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 10.1%, Avg loss: 2.312671 \n",
      "\n",
      "1-------------------\n",
      "624 1445.3639233112335\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 10.2%, Avg loss: 2.312744 \n",
      "\n",
      "2-------------------\n",
      "624 1445.372773885727\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 10.2%, Avg loss: 2.312512 \n",
      "\n",
      "3-------------------\n",
      "624 1445.2683897018433\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 10.3%, Avg loss: 2.312483 \n",
      "\n",
      "4-------------------\n",
      "624 1445.261562347412\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 10.2%, Avg loss: 2.312901 \n",
      "\n",
      "5-------------------\n",
      "624 1445.2282328605652\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 10.2%, Avg loss: 2.312506 \n",
      "\n",
      "6-------------------\n",
      "624 1445.1435956954956\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 10.2%, Avg loss: 2.312661 \n",
      "\n",
      "7-------------------\n",
      "624 1445.1200420856476\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 10.2%, Avg loss: 2.312506 \n",
      "\n",
      "8-------------------\n",
      "624 1445.037868976593\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 10.3%, Avg loss: 2.312154 \n",
      "\n",
      "9-------------------\n",
      "624 1445.0047059059143\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 10.3%, Avg loss: 2.312136 \n",
      "\n",
      "Le taux de learning est de 1e-09\n",
      "0-------------------\n",
      "624 1445.4727199077606\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 10.1%, Avg loss: 2.312742 \n",
      "\n",
      "1-------------------\n",
      "624 1445.4314393997192\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 10.1%, Avg loss: 2.312888 \n",
      "\n",
      "2-------------------\n",
      "624 1445.4854476451874\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 10.1%, Avg loss: 2.312726 \n",
      "\n",
      "3-------------------\n",
      "624 1445.4259598255157\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 10.2%, Avg loss: 2.312767 \n",
      "\n",
      "4-------------------\n",
      "624 1445.4641761779785\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 10.1%, Avg loss: 2.313265 \n",
      "\n",
      "5-------------------\n",
      "624 1445.4758269786835\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 10.1%, Avg loss: 2.312936 \n",
      "\n",
      "6-------------------\n",
      "624 1445.4361357688904\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 10.1%, Avg loss: 2.313166 \n",
      "\n",
      "7-------------------\n",
      "624 1445.4579257965088\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 10.1%, Avg loss: 2.313081 \n",
      "\n",
      "8-------------------\n",
      "624 1445.4195890426636\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 10.2%, Avg loss: 2.312792 \n",
      "\n",
      "9-------------------\n",
      "624 1445.4318990707397\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 10.2%, Avg loss: 2.312849 \n",
      "\n",
      "0.001\n"
     ]
    }
   ],
   "source": [
    "list_learning_rate = [0.001,0.0001, 1e-5,  1e-6 ,1e-7, 1e-8,  1e-9]\n",
    "lr_rate_opt = fonction_renvoie_lr_rate(list_learning_rate =list_learning_rate,\\\n",
    "                                       device = device, modele = LeNet5Color, train = train_color,\\\n",
    "                                       val = val_color, number_class = None, loss_fn=loss_fn)\n",
    "print(lr_rate_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "cf4a3479-bd80-4e12-a3f5-03a1f0ebe02a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cf4a3479-bd80-4e12-a3f5-03a1f0ebe02a",
    "outputId": "e85d4cfb-f077-4769-f80d-15d7350d3ccb",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0-------------------\n",
      "624 971.0558356046677\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 50.0%, Avg loss: 1.368531 \n",
      "\n",
      "1-------------------\n",
      "624 810.7250182032585\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 52.8%, Avg loss: 1.320182 \n",
      "\n",
      "2-------------------\n",
      "624 740.5806648135185\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 55.2%, Avg loss: 1.259036 \n",
      "\n",
      "3-------------------\n",
      "624 690.3418020009995\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 58.0%, Avg loss: 1.185136 \n",
      "\n",
      "4-------------------\n",
      "624 649.8410103321075\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 60.1%, Avg loss: 1.117086 \n",
      "\n",
      "5-------------------\n",
      "624 615.1594572067261\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 61.2%, Avg loss: 1.103161 \n",
      "\n",
      "6-------------------\n",
      "624 587.0130043625832\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 60.9%, Avg loss: 1.123868 \n",
      "\n",
      "7-------------------\n",
      "624 565.7222177684307\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 60.9%, Avg loss: 1.116621 \n",
      "\n",
      "8-------------------\n",
      "624 540.3675037026405\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 63.5%, Avg loss: 1.036832 \n",
      "\n",
      "9-------------------\n",
      "624 519.1642889678478\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 62.2%, Avg loss: 1.103504 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "reseau_cnn_color = LeNet5Color().to(device)\n",
    "optimizerNet = torch.optim.Adam(reseau_cnn_color.parameters(), lr = lr_rate_opt)\n",
    "\n",
    "torch.manual_seed(133)\n",
    "\n",
    "for epoch in range(0,10):\n",
    "    print(str(epoch)+\"-------------------\")\n",
    "    train_loop(dataloader=train_color,optimizer=optimizerNet,loss_fn=loss_fn,modele=reseau_cnn_color,device=device)\n",
    "    evaluate_loop(dataloader=test_color,loss_fn=loss_fn,model=reseau_cnn_color,device=device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8456b1db-6930-49cc-9515-ea261fc7fc70",
   "metadata": {},
   "source": [
    "# Comparaison of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9f6e90e1-34f0-4ab0-bd7e-dbc41a4d747c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of parameter for  LeNet5Color model is 61750.\n",
      "They have the same performance.\n"
     ]
    }
   ],
   "source": [
    "total_params_reseau_cnn_color=sum(p.numel() for p in reseau_cnn.parameters())\n",
    "print(f'The number of parameters for  LeNet5Color model is {total_params_reseau_cnn_color}.')\n",
    "print(\"The two models have the same performance.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74fa2d43-fea2-4615-940f-a831e1438bfc",
   "metadata": {
    "id": "74fa2d43-fea2-4615-940f-a831e1438bfc",
    "scrolled": true
   },
   "source": [
    "## Exercise 12\n",
    "- Randomly take 10 examples from each class of CIFAR10 to make a subset (*) of the dataset.\n",
    "- Load this model ResNet18 pre-trained on ImageNet v1 which is available from `torchvision.models`. See [this](https://pytorch.org/vision/stable/models.html) and [this documentation](https://pytorch.org/vision/stable/models/generated/torchvision.models.resnet18.html#torchvision.models.resnet18).\n",
    "- Fine-tune the pre-trained model for 10-class classification with your subset (from (*)) of CIFAR10 (with colors). Train the model for 5 epochs.\n",
    "- You may need to carefully read [this documentation](https://pytorch.org/vision/stable/models/generated/torchvision.models.resnet18.html#torchvision.models.resnet18) to do the right data pre-processing.\n",
    "\n",
    "For this exercise, what is important is to have correct code. The final accuracy is less important, so you don't need to spend too much time on tuning hyper-parameters. There is a big difference in the image sizes, and it is challenging to make this transfer learning successful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "86d42a85-b818-4cfe-93aa-bfcde12005ad",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "86d42a85-b818-4cfe-93aa-bfcde12005ad",
    "outputId": "64537ce3-f50e-4ae1-e97e-8037deb899c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tuple'>\n"
     ]
    }
   ],
   "source": [
    "Base = load_cifar10(train = True)\n",
    "print(type(Base))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e980e30f-5c36-4446-8a96-20f2fa121537",
   "metadata": {},
   "source": [
    "# Creating of the train , validation and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "102da1fd-7021-421c-b9c7-b38320f095f2",
   "metadata": {
    "id": "102da1fd-7021-421c-b9c7-b38320f095f2"
   },
   "outputs": [],
   "source": [
    "x_train_res=[]\n",
    "y_train_res=[]\n",
    "test=[]\n",
    "for y in np.unique(y_train_np_color):\n",
    "    sous_ensemble=np.where(y_train_np_color==y)[0]\n",
    "    indices=np.random.choice(sous_ensemble,10, replace =False )\n",
    "    mini_x=x_train_np_color[indices]\n",
    "    mini_y=y_train_np_color[indices]\n",
    "    x_train_res.extend(mini_x)\n",
    "    y_train_res.extend(mini_y)\n",
    "\n",
    "x_train_res = np.array(x_train_res)\n",
    "y_train_res = np.array(y_train_np)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "48c42aa1-312e-4769-bf48-b5b897995784",
   "metadata": {
    "id": "48c42aa1-312e-4769-bf48-b5b897995784"
   },
   "outputs": [],
   "source": [
    "def sample_grp_y(x_base,y_base):\n",
    "    x_sample=[]\n",
    "    y_sample=[]\n",
    "    for y in np.unique(y_base):\n",
    "        sous_ensemble=np.where(y_base==y)[0]\n",
    "        indices=np.random.choice(sous_ensemble, 10, replace=False)\n",
    "        mini_x=x_base[indices]\n",
    "        mini_y=y_base[indices]\n",
    "        x_sample.extend(mini_x)\n",
    "        y_sample.extend(mini_y)\n",
    "    x_sample=np.array(x_sample)\n",
    "    y_sample=np.array(y_sample)\n",
    "    return(x_sample,y_sample)\n",
    "\n",
    "sample_x,sample_y=sample_grp_y(x_train_np_color,y_train_np_color)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "c58fe587-6a0d-471e-ba99-2fcd33ad65a8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c58fe587-6a0d-471e-ba99-2fcd33ad65a8",
    "outputId": "c51aa60c-fc28-4755-c15b-febcd11f46d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56,)\n"
     ]
    }
   ],
   "source": [
    "sample_train_x,sample_test_x, sample_train_y,sample_test_y=train_test_split(sample_x,sample_y,random_state=6)\n",
    "sample_train_x,sample_val_x,sample_train_y,sample_val_y=train_test_split(sample_train_x,sample_train_y,random_state=6)\n",
    "print(sample_train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "e4b48781-7b01-45a4-b6a4-1cd8320c4cd4",
   "metadata": {
    "id": "e4b48781-7b01-45a4-b6a4-1cd8320c4cd4"
   },
   "outputs": [],
   "source": [
    "sample_train_x=torch.from_numpy(sample_train_x).to(dtype=torch.float32)\n",
    "sample_val_x=torch.from_numpy(sample_val_x).to(dtype=torch.float32)\n",
    "sample_test_x=torch.from_numpy(sample_test_x).to(dtype=torch.float32)\n",
    "\n",
    "sample_train_y=torch.from_numpy(sample_train_y).to(dtype=torch.int64)\n",
    "sample_val_y=torch.from_numpy(sample_val_y).to(dtype=torch.int64)\n",
    "sample_test_y=torch.from_numpy(sample_test_y).to(dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "02249e62-d227-47f8-ab12-f53cfd32b92b",
   "metadata": {
    "id": "02249e62-d227-47f8-ab12-f53cfd32b92b"
   },
   "outputs": [],
   "source": [
    "from torchvision.models import resnet18\n",
    "\n",
    "model = resnet18().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4fcb91-752b-4bf6-b25f-70924c614b7d",
   "metadata": {},
   "source": [
    "# Preprossessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "64ce1242-6bbf-4fa9-9b08-774472860fc5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "64ce1242-6bbf-4fa9-9b08-774472860fc5",
    "outputId": "b014b889-543b-4194-cae0-0f5825ee2f63"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/mamba/lib/python3.11/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from torchvision.models import ResNet18_Weights\n",
    "preprocess=ResNet18_Weights.DEFAULT.transforms()\n",
    "## preprocessing\n",
    "sample_train_x=preprocess(sample_train_x)\n",
    "sample_val_x=preprocess(sample_val_x)\n",
    "sample_test_x=preprocess(sample_test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "0192320b-91ca-4c38-972c-6bd09836184d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0192320b-91ca-4c38-972c-6bd09836184d",
    "outputId": "0a60afac-d0c9-4036-ab0c-1b2dd9e2930d"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(133)\n",
    "\n",
    "train_sample = DataLoader(CustomDataset(sample_train_x,sample_train_y), batch_size=10, shuffle =True)\n",
    "test_sample = DataLoader(CustomDataset(sample_test_x,sample_test_y), batch_size=10, shuffle =True)\n",
    "val_sample = DataLoader(CustomDataset(sample_val_x,sample_val_y), batch_size=10, shuffle =True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d4fcca-6eb8-4b2e-8f40-2a81eb1eeda1",
   "metadata": {},
   "source": [
    "# Turning of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "e0b31352-b745-4195-8858-fce5c648542e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e0b31352-b745-4195-8858-fce5c648542e",
    "outputId": "c22ce895-0fd6-4faf-b80e-0b81d2077fc2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le taux de learning est de 0.001\n",
      "0-------------------\n",
      "5 32.720848083496094\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 10.5%, Avg loss: 916.887756 \n",
      "\n",
      "1-------------------\n",
      "5 18.799569845199585\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 10.5%, Avg loss: 233.394897 \n",
      "\n",
      "2-------------------\n",
      "5 11.682804107666016\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 5.3%, Avg loss: 25.279130 \n",
      "\n",
      "3-------------------\n",
      "5 10.854404091835022\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 0.0%, Avg loss: 12.124784 \n",
      "\n",
      "4-------------------\n",
      "5 10.15961492061615\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 10.5%, Avg loss: 20.120780 \n",
      "\n",
      "Le taux de learning est de 0.0001\n",
      "0-------------------\n",
      "5 39.496646881103516\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 10.5%, Avg loss: 16.763386 \n",
      "\n",
      "1-------------------\n",
      "5 31.40471839904785\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 15.8%, Avg loss: 10.345893 \n",
      "\n",
      "2-------------------\n",
      "5 23.47116208076477\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 10.5%, Avg loss: 7.077272 \n",
      "\n",
      "3-------------------\n",
      "5 18.435404062271118\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 0.0%, Avg loss: 5.547614 \n",
      "\n",
      "4-------------------\n",
      "5 16.324249029159546\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 10.5%, Avg loss: 6.666584 \n",
      "\n",
      "Le taux de learning est de 1e-05\n",
      "0-------------------\n",
      "5 41.19969606399536\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 0.0%, Avg loss: 9.082502 \n",
      "\n",
      "1-------------------\n",
      "5 40.559367179870605\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 0.0%, Avg loss: 7.007143 \n",
      "\n",
      "2-------------------\n",
      "5 39.22303915023804\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 0.0%, Avg loss: 6.818001 \n",
      "\n",
      "3-------------------\n",
      "5 38.29726839065552\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 0.0%, Avg loss: 6.777407 \n",
      "\n",
      "4-------------------\n",
      "5 37.84635019302368\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 5.3%, Avg loss: 6.693387 \n",
      "\n",
      "Le taux de learning est de 1e-06\n",
      "0-------------------\n",
      "5 41.36409378051758\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 0.0%, Avg loss: 9.345729 \n",
      "\n",
      "1-------------------\n",
      "5 41.5997371673584\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 0.0%, Avg loss: 7.171938 \n",
      "\n",
      "2-------------------\n",
      "5 41.11703300476074\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 0.0%, Avg loss: 7.023680 \n",
      "\n",
      "3-------------------\n",
      "5 41.13886880874634\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 0.0%, Avg loss: 7.030338 \n",
      "\n",
      "4-------------------\n",
      "5 41.170989990234375\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 0.0%, Avg loss: 7.021339 \n",
      "\n",
      "Le taux de learning est de 1e-07\n",
      "0-------------------\n",
      "5 41.3811469078064\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 0.0%, Avg loss: 9.374129 \n",
      "\n",
      "1-------------------\n",
      "5 41.70374536514282\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 0.0%, Avg loss: 7.190502 \n",
      "\n",
      "2-------------------\n",
      "5 41.303295612335205\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 0.0%, Avg loss: 7.045289 \n",
      "\n",
      "3-------------------\n",
      "5 41.42129325866699\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 0.0%, Avg loss: 7.055764 \n",
      "\n",
      "4-------------------\n",
      "5 41.50400733947754\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 0.0%, Avg loss: 7.053728 \n",
      "\n",
      "Le taux de learning est de 1e-08\n",
      "0-------------------\n",
      "5 41.38285160064697\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 0.0%, Avg loss: 9.376997 \n",
      "\n",
      "1-------------------\n",
      "5 41.714162826538086\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 0.0%, Avg loss: 7.192412 \n",
      "\n",
      "2-------------------\n",
      "5 41.32193565368652\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 0.0%, Avg loss: 7.047450 \n",
      "\n",
      "3-------------------\n",
      "5 41.44947957992554\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 0.0%, Avg loss: 7.058301 \n",
      "\n",
      "4-------------------\n",
      "5 41.53737497329712\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 0.0%, Avg loss: 7.056967 \n",
      "\n",
      "Le taux de learning est de 1e-09\n",
      "0-------------------\n",
      "5 41.383026123046875\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 0.0%, Avg loss: 9.377295 \n",
      "\n",
      "1-------------------\n",
      "5 41.71524143218994\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 0.0%, Avg loss: 7.192611 \n",
      "\n",
      "2-------------------\n",
      "5 41.32387399673462\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 0.0%, Avg loss: 7.047675 \n",
      "\n",
      "3-------------------\n",
      "5 41.45242357254028\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 0.0%, Avg loss: 7.058566 \n",
      "\n",
      "4-------------------\n",
      "5 41.540865898132324\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 0.0%, Avg loss: 7.057307 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "list_learningRate = [0.001,0.0001, 1e-5,  1e-6 ,1e-7, 1e-8,  1e-9]\n",
    "\n",
    "for learningRate in list_learningRate :\n",
    "    model = resnet18().to(device)\n",
    "    optimizerNet = torch.optim.Adam(model.parameters(), lr = learningRate)\n",
    "    print(f\"Le taux de learning est de {learningRate}\")\n",
    "    liste_precision=[]\n",
    "    torch.manual_seed(133)\n",
    "    for epoch in range(5):\n",
    "        print(str(epoch)+\"-------------------\")\n",
    "        train_loop(dataloader=train_sample,optimizer=optimizerNet,loss_fn=loss_fn,modele=model,device=device)\n",
    "        precision = evaluate_loop(dataloader=val_sample,loss_fn=loss_fn,model=model,device=device)\n",
    "        precision_un_taux.append(precision)\n",
    "    selection=np.mean(np.array(precision_un_taux))\n",
    "    liste_precision.append(selection)\n",
    "indice=np.argmax(np.array(liste_precision))\n",
    "lr_rate_optresnet=list_learning_rate[indice]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf67d5e-44b0-474e-8ba9-72587aa2cd02",
   "metadata": {},
   "source": [
    "# Computing the accuracy in the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "n57LzFc_MsaZ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n57LzFc_MsaZ",
    "outputId": "48e4053a-c586-413a-b1f8-bdc92418e6ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le taux de learning est de 0.001\n",
      "0-------------------\n",
      "5 33.107598066329956\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 20.0%, Avg loss: 480.656759 \n",
      "\n",
      "1-------------------\n",
      "5 18.566736936569214\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 20.0%, Avg loss: 110.559371 \n",
      "\n",
      "2-------------------\n",
      "5 12.342234373092651\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 20.0%, Avg loss: 61.661366 \n",
      "\n",
      "3-------------------\n",
      "5 10.621351718902588\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 12.0%, Avg loss: 15.557113 \n",
      "\n",
      "4-------------------\n",
      "5 10.89992368221283\n",
      "\n",
      "Validation set: \n",
      "  Accuracy: 20.0%, Avg loss: 4.666917 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = resnet18().to(device)\n",
    "optimizerNet = torch.optim.Adam(model.parameters(), lr = lr_rate_optresnet)\n",
    "print(f\"Le taux de learning est de {lr_rate_optresnet}\")\n",
    "liste_precision=[]\n",
    "\n",
    "torch.manual_seed(133)\n",
    "\n",
    "for epoch in range(5):\n",
    "      print(str(epoch)+\"-------------------\")\n",
    "      train_loop(dataloader=train_sample,optimizer=optimizerNet,loss_fn=loss_fn,modele=model,device=device)\n",
    "      precision = evaluate_loop(dataloader=test_sample,loss_fn=loss_fn,model=model,device=device)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
